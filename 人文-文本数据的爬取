import requests
from bs4 import BeautifulSoup
# 导入了两个必要的库
# requests 库用于发送 HTTP 请求，从指定的 URL 获取网页内容
# BeautifulSoup 来自 bs4 库，用于解析 HTML 或 XML 格式的文档，方便提取其中的信息

URL = 'http://renwen.sanyau.edu.cn'
# 定义了一个字符串变量 URL 为要爬取的三亚学院人文与传播学院的网页地址

headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}
# 创建了一个字典 headers，其中包含了 User-Agent 的 HTTP 请求头部分，用于标识客户端（这里是模拟浏览器）的信息
# 设置这个字段是为了伪装成正常的浏览器请求，以避免人文学院的反爬虫机制拒绝我们的请求

rq = requests.get(url=URL, headers=headers)
# 使用 requests 库发送一个 GET 请求到指定的 url，并将请求头 headers 传递过去
# 并把服务器响应的结果存储在变量 rq 中

rq.encoding = rq.apparent_encoding
# 自动检测网页内容的编码方式，并将其设置为响应对象 rq 的编码，确保后续解析和显示的文本内容不出现乱码

soup = BeautifulSoup(rq.text, 'lxml')
# 使用 BeautifulSoup 类将获取到的网页内容（rq.text）用 lxml 作为解析器解析为一个可操作的对象

titles = soup.select('div[class="text"]')
# 查找所有 class 属性为 text 的 div 元素，并将结果存储在 titles 列表里

print(titles)
# 将 titles 列表打印出来，方便查看所获取到的内容

with open('renwenxinwen.txt', 'a', encoding='utf-8') as f:
# 打开一个名为 renwenxinwen.txt 的文件，并指定编码为 utf-8
    for title in titles:
# 遍历 titles 列表中的每个元素 title
        print(title.text)
# 打印 title 的文本内容
        f.writelines(title.text + '\r')
# 将上面的文本内容写入到文件中，并在每个内容后添加一个回车符
